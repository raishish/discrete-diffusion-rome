# Stores the model configurations
# Ref: https://github.com/ML-GSAI/SMDM/blob/main/lit_gpt/config.py

from typing import Any
from litgpt.config import Config


diff_llama_configs = [
    dict(
        name="Diff_LLaMA_6M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-6M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=6,
        n_head=4,
        n_embd=256,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=1024,
        n_query_groups=4,
    ),
    dict(
        name="Diff_LLaMA_19M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-19M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=8,
        n_head=6,
        n_embd=384,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=1536,
        n_query_groups=6,
    ),
    dict(
        name="Diff_LLaMA_34M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-34M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=8,
        n_head=8,
        n_embd=512,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=2048,
        n_query_groups=8,
    ),
    dict(
        name="Diff_LLaMA_48M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-48M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=9,
        n_head=9,
        n_embd=576,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=2304,
        n_query_groups=9,
    ),
    dict(
        name="Diff_LLaMA_66M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-66M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=10,
        n_head=10,
        n_embd=640,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=2560,
        n_query_groups=10,
    ),
    dict(
        name="Diff_LLaMA_85M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-85M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=13,
        n_head=10,
        n_embd=640,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=2560,
        n_query_groups=10,
    ),
    dict(
        name="Diff_LLaMA_75M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-75M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=16,
        n_head=8,
        n_embd=640,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=1600,
        n_query_groups=8,
    ),
    dict(
        name="Diff_LLaMA_113M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-113M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=12,
        n_head=12,
        n_embd=768,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3072,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_142M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-142M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=15,
        n_head=12,
        n_embd=768,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3072,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_170M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-170M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=18,
        n_head=12,
        n_embd=768,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3072,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_180M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-180M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=14,
        n_head=14,
        n_embd=896,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3584,
        n_query_groups=14,
    ),
    dict(
        name="Diff_LLaMA_206M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-206M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=16,
        n_head=14,
        n_embd=896,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3584,
        n_query_groups=14,
    ),
    dict(
        name="Diff_LLaMA_231M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-231M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=18,
        n_head=14,
        n_embd=896,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=3584,
        n_query_groups=14,
    ),
    dict(
        name="Diff_LLaMA_268M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-268M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=16,
        n_head=16,
        n_embd=1024,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=4096,
        n_query_groups=16,
    ),
    dict(
        name="Diff_LLaMA_302M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-302M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=18,
        n_head=16,
        n_embd=1024,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=4096,
        n_query_groups=16,
    ),
    dict(
        name="Diff_LLaMA_336M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-336M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=20,
        n_head=16,
        n_embd=1024,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=4096,
        n_query_groups=16,
    ),
    dict(
        name="Diff_LLaMA_472M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-472M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=18,
        n_head=10,
        n_embd=1280,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=5120,
        n_query_groups=10,
    ),
    dict(
        name="Diff_LLaMA_551M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-551M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=21,
        n_head=10,
        n_embd=1280,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=5120,
        n_query_groups=10,
    ),
    dict(
        name="Diff_LLaMA_571M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-571M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=18,
        n_head=11,
        n_embd=1408,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=5632,
        n_query_groups=11,
    ),
    dict(
        name="Diff_LLaMA_629M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-629M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=24,
        n_head=10,
        n_embd=1280,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,
        mlp_class_name="LLaMAMLP",
        intermediate_size=5120,
        n_query_groups=10,
    ),
    dict(
        name="Diff_LLaMA_666M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-666M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=21,
        n_head=11,
        n_embd=1408,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=5632,
        n_query_groups=11,
    ),
    dict(
        name="Diff_LLaMA_717M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-717M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=19,
        n_head=12,
        n_embd=1536,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=6144,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_761M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-761M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=24,
        n_head=11,
        n_embd=1408,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=5632,
        n_query_groups=11,
    ),
    dict(
        name="Diff_LLaMA_831M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-831M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=22,
        n_head=12,
        n_embd=1536,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=6144,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_944M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-944M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=25,
        n_head=12,
        n_embd=1536,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=6144,
        n_query_groups=12,
    ),
    dict(
        name="Diff_LLaMA_1028M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-1028M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=20,
        n_head=14,
        n_embd=1792,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=7168,
        n_query_groups=14,
    ),
    dict(
        name="Diff_LLaMA_1233M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-1233M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=24,
        n_head=14,
        n_embd=1792,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=7168,
        n_query_groups=14,
    ),
    dict(
        name="Diff_LLaMA_1476M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-1476M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=22,
        n_head=16,
        n_embd=2048,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=8192,
        n_query_groups=16,
    ),
    dict(
        name="Diff_LLaMA_1678M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-1678M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=25,
        n_head=16,
        n_embd=2048,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=8192,
        n_query_groups=16,
    ),
    dict(
        name="Diff_LLaMA_2121M",
        hf_config=dict(org="ML-GSAI", name="Diff-LLaMA-2121M"),
        block_size=2048,
        vocab_size=32000,
        padding_multiple=64,
        n_layer=28,
        n_head=17,
        n_embd=2176,
        rotary_percentage=1,
        parallel_residual=False,
        bias=False,
        norm_class_name="RMSNorm",
        norm_eps=1e-5,  # Llama 2 use 1e-5. Llama 1 use 1e-6
        mlp_class_name="LLaMAMLP",
        intermediate_size=8704,
        n_query_groups=17,
    ),
]
name_to_config = {config["name"]: config for config in diff_llama_configs}


def get_config_class(name: str, **kwargs: Any):
    """Get the model config class from a model name."""
    try:
        config = name_to_config[name].copy()
    except KeyError:
        raise ValueError(f"Unsupported model name: \"{name}\". Choose one from: {list(name_to_config.keys())}")

    config.update(kwargs)
    return Config(**config)  # type: ignore
